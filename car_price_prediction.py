# -*- coding: utf-8 -*-
"""car_price_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U95zIMtj1-NpbXb10dJ1HsLI69Il76cI

#Importing all the necessary Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn

"""#Data Gathering"""

df = pd.read_csv("car_data.csv")
df.head()

"""#Data Preparation"""

df.info()

df.shape

df.isnull().sum()

df.dtypes

"""#Feature Engineering"""

categorical_col = ['Fuel_Type', 'Seller_Type', 'Transmission']
numeric_col = ['Year', 'Selling_Price', 'Present_Price', 'Kms_Driven', 'Owner']
print(categorical_col)
print(numeric_col)

df1=df

df1 = pd.get_dummies(df1, columns=categorical_col, drop_first=True)
df1.head()

df1.drop(columns=['Car_Name'], axis="columns", inplace=True)

df1.head()

import scipy.stats as stats
z = np.abs(stats.zscore(df1))

#only keep rows in dataframe with all z-scores less than absolute value of 3 
data_clean = df1[(z<3).all(axis=1)]

#find how many rows are left in the dataframe 
data_clean.shape

'''
for col in data_clean.columns:
  col_zscore = col + '_zscore'
  data_clean[col_zscore] = (data_clean[col] - data_clean[col].mean())/data_clean[col].std()
  col_outlier = col + '_outlier'
  data_clean[col_outlier] = (abs(data_clean[col_zscore]>3)).astype('int')

data_clean.head()
'''

df1.shape

data_clean.shape

df1=data_clean

df1.shape

df1.head()

df1['current_year'] = 2021

#we have to check how old our car
df1['no_year'] = df1['current_year'] - df1['Year']
df1.head()

df1.drop(columns=['current_year'], axis='columns', inplace=True)

df1.drop(columns=['Owner'], axis='columns', inplace=True)

df1.corr()

import seaborn as sns
plt.figure(figsize=(8,8))
sns.heatmap(df1.corr(), annot=True, cmap='Blues', fmt=".2f", linewidths=2)

sns.PairGrid(df1, vars = ['Year', 'Selling_Price', 'Present_Price']).map(plt.scatter)

"""#Features and Target Variables"""

x = df1.drop(columns=['Selling_Price'], axis='columns')
y = df1['Selling_Price']

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.30, random_state=5)

"""#Feature Importance"""

# it will tell that which feature is more important

from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor()
model.fit(x, y)

print(model.feature_importances_)

feat_imp = pd.Series(model.feature_importances_, index=x.columns)

feat_imp.nlargest(5).plot(kind='barh')  #here we can see Present_Price feature has greator importance

"""#Fitting and Evaluating diffrent models

Here I am using three models:

1: Linear Regression

2: Decision Tree

3: Random Forest Regressor

#Linear Regression
"""

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
mymodel = lr.fit(xtrain, ytrain)
mymodel

ypred = mymodel.predict(xtest)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"MAE: {round(mean_absolute_error(ytest, ypred),2)}")
print(f"MSE: {round(mean_squared_error(ytest, ypred),2)}")
print(f"RMSE: {round(np.sqrt(mean_squared_error(ytest, ypred)),2)}")
print(f"R2: {round(r2_score(ytest, ypred),2)}")

"""#Random Forest"""

#random forest is a enhanced version of desicion tree
# in random forest we build number of decision tree.

from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor()
mymodel_rf = rf.fit(xtrain, ytrain)
mymodel_rf

ypred = mymodel_rf.predict(xtest)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"MAE: {round(mean_absolute_error(ytest, ypred),2)}")
print(f"MSE: {round(mean_squared_error(ytest, ypred),2)}")
print(f"RMSE: {round(np.sqrt(mean_squared_error(ytest, ypred)),2)}")
print(f"R2: {round(r2_score(ytest, ypred),2)}")

"""#Decision Tree"""

from sklearn.tree import DecisionTreeRegressor
dt = DecisionTreeRegressor()
mymodel_dt = dt.fit(xtrain, ytrain)
mymodel_dt

ypred = mymodel_dt.predict(xtest)

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
print(f"MAE: {round(mean_absolute_error(ytest, ypred),2)}")
print(f"MSE: {round(mean_squared_error(ytest, ypred),2)}")
print(f"RMSE: {round(np.sqrt(mean_squared_error(ytest, ypred)),2)}")
print(f"R2: {round(r2_score(ytest, ypred),2)}")

"""###we want R2 score should be maximum and other error should be minimum

###Random forest regressor is giving better result. therefore we will hypertune this model and then fit, predict.
"""

#Hyper Parameter Tuning

#hyperparameter can be done by two ways 1: GridSearchCV  2: RandomizedSearchCV
#we use RandomizedSearchCV because GridSearchCV is slow

#n_estimators = number of trees in the forest
n_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]
print(n_estimators)

from sklearn.model_selection import RandomizedSearchCV

n_estimators = [int(x) for x in np.linspace(start=100, stop=1200, num=12)]
criterion = ['mse', 'mae']
max_depth = [int(x) for x in np.linspace(start=5, stop=30, num=6)]
min_samples_split = [2, 5, 10, 100]
min_samples_leaf = [1, 2, 5, 10]

#create a random grid

random_grid = {"n_estimators": n_estimators, "criterion": criterion, "max_depth": max_depth, "min_samples_split": min_samples_split, "min_samples_leaf": min_samples_leaf}
print(random_grid)

# use the random grid to search for best Hyperparameters
# First Create a best model to tune
rf = RandomForestRegressor()

# Random search of parameters, using 5 fold cross validation
# search across different 100 combination
rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100, scoring='neg_mean_squared_error', cv=5, verbose=2, random_state=42, n_jobs=1)

#fit the random forest model
rf_random.fit(xtrain, ytrain)

#displaying the best parameters
rf_random.best_params_

rf_random.best_score_

"""#Final Prediction"""

ypred = rf_random.predict(xtest)

pd.DataFrame({"Actual": ytest, "Predict": np.round(ypred, 2)}).head(10)

print(f"MSE: {mean_squared_error(ytest, ypred)}")
print(f"MAE: {mean_absolute_error(ytest, ypred)}")
print(f"RMSE: {np.sqrt(mean_squared_error(ytest, ypred))}")
print(f"R2: {r2_score(ytest, ypred)}")

"""#Save Model"""

from sklearn.externals import joblib
joblib.dump(rf_random, 'model_j')
model_j = joblib.load('model_j')

x.head()

